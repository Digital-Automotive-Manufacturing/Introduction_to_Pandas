{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5ab459c-9253-46c8-8cec-e5ed61533c51",
   "metadata": {},
   "source": [
    "# Introduction to Python Pandas Library <a id='Start'></a>\n",
    "\n",
    "The objective of this assignment is to provide an overview of the Python Pandas Library and its fundamentals. After completing this assignment, you should be able to understand and use the library effectively for data analysis and manipulation. This is not an all encompassing overview. There are additional functions that we will cover in the class and many that we will not cover. \n",
    "\n",
    "Use the links below to move to each section of the notebook directly.\n",
    "\n",
    "Introduction to Pandas:\n",
    "- [What is Pandas?](#Pandas)\n",
    "- Features of Pandas.\n",
    "\n",
    "Pandas Data Structures:\n",
    "- [Series](#Series): Creating a series, indexing, accessing elements.\n",
    "- [DataFrame](#DataFrame): Creating a DataFrame, indexing, accessing elements, data manipulation.\n",
    "\n",
    "Data Import and Export:\n",
    "- [Writing](#Write) data to a CSV file.\n",
    "- [Reading](#Read) data from a CSV file.\n",
    "\n",
    "Data Manipulation:\n",
    "- [Viewing](#View) data.\n",
    "- [Describing](#View) data.\n",
    "- [Selecting](#Select) data.\n",
    "- [Sorting](#Sort) data.\n",
    "- [Filtering](#Filter) data.\n",
    "- [Merging](#Merge) data.\n",
    "- [Grouping](#Group) data.\n",
    "- [Aggregating](#Aggregate) data.\n",
    "\n",
    "Data Visualization:\n",
    "- [Plotting](#Plot) Pandas data.\n",
    "\n",
    "Go to [End](#End)\n",
    "\n",
    "Resources:\n",
    "\n",
    "- Pandas documentation: https://pandas.pydata.org/docs/\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4269735-216e-4026-9cce-8e6361283814",
   "metadata": {},
   "source": [
    "## What is the Pandas library? <a name=\"Pandas\"></a>\n",
    "\n",
    "Pandas is a popular open-source Python library used for data manipulation, analysis, and visualization. It provides high-performance, easy-to-use data structures and data analysis tools that make working with structured data fast, easy, and efficient. Pandas can handle a wide variety of data formats including tabular data (in CSV, Excel, or SQL database formats), time series data, and multidimensional data with ease. The library provides a variety of data manipulation functions such as merging, reshaping, and filtering, as well as statistical and mathematical functions for data analysis. Pandas also has built-in data visualization capabilities, making it a powerful tool for exploratory data analysis. Overall, Pandas is a powerful and essential tool for any data analyst, data scientist, or machine learning engineer working with Python.\n",
    "\n",
    "### Features of Pandas: \n",
    "Some of the key features of Pandas are:\n",
    "\n",
    "- <ins>Input/Output</ins>: Pandas provides functions for reading and writing data in a variety of formats, including CSV, Excel, SQL, JSON, and more.\n",
    "\n",
    "- <ins>Data Structures</ins>: Pandas provides two main data structures - Series and DataFrame - which are powerful, flexible, and efficient for storing and manipulating data.\n",
    "\n",
    "- <ins>Data Manipulation</ins>: Pandas has a wide range of functions for filtering, grouping, reshaping, pivoting, merging, and sorting data, making it easy to transform and manipulate data.\n",
    "\n",
    "- <ins>Grouping and aggregation</ins>: Pandas provides methods to group data based on one or more columns and perform aggregation functions such as sum, mean, min, max, count, and more.\n",
    "\n",
    "- <ins>Data Cleaning</ins>: Pandas has functions for handling missing data, removing duplicates, and correcting erroneous data, making it easy to clean up data before analysis.\n",
    "\n",
    "- <ins>Time Series Analysis</ins>: Pandas provides powerful tools for working with time series data, including date and time functions, resampling, and windowing functions.\n",
    "\n",
    "- <ins>Data Visualization</ins>: Pandas has built-in data visualization capabilities, making it easy to create a wide range of plots and charts for exploratory data analysis.\n",
    "\n",
    "\n",
    "Pandas gives you answers about the data. Like:\n",
    "\n",
    "- Is there a correlation between two or more columns?\n",
    "- What is average value?\n",
    "- Max value?\n",
    "- Min value?\n",
    "\n",
    "Pandas are also able to delete rows that are not relevant, or contains wrong values, like empty or NULL values. This is called cleaning the data.\n",
    "***\n",
    "\n",
    "### Import Pandas\n",
    "\n",
    "Pandas is imported like other Python libraries by adding the import keyword:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2659e344-496f-4758-936f-3536b5eb7221",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30211e26-c1fc-4c3e-9c97-e22c0bf038de",
   "metadata": {},
   "source": [
    "Now Pandas is imported and ready to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af49c3cc-53d9-4f6b-9b4f-25a8213fad9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "mydataset = {\n",
    "  'cars': [\"BMW\", \"Volvo\", \"Ford\"],\n",
    "  'passings': [3, 7, 2]\n",
    "}\n",
    "\n",
    "myvar = pandas.DataFrame(mydataset)\n",
    "\n",
    "print(myvar) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e1fc9b-3833-4069-941c-1f7841345ddf",
   "metadata": {},
   "source": [
    "Pandas is commonly imported under the pd alias.\n",
    "\n",
    "Create an alias with the as keyword while importing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2da68c-a51b-458b-9d2b-73483ab78a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cb373c-c594-4923-a7f9-2e98f4efff44",
   "metadata": {},
   "source": [
    "Now the Pandas package can be referred to as pd instead of pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99fd6bd-b6a6-411d-95b6-936ed6203e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "mydataset = {\n",
    "  'cars': [\"BMW\", \"Volvo\", \"Ford\"],\n",
    "  'passings': [3, 7, 2]\n",
    "}\n",
    "\n",
    "myvar = pd.DataFrame(mydataset)\n",
    "\n",
    "print(myvar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac802177-147a-4d10-9d0c-86764ec0d91b",
   "metadata": {},
   "source": [
    "[Return to top](#Start)\n",
    "***\n",
    "\n",
    "## Pandas Data Structures\n",
    "Data in Pandas is held in two types of structures, Series or DataFrames.\n",
    "\n",
    "### Series <a name=\"Series\"></a>\n",
    "\n",
    "Series documentation: https://pandas.pydata.org/docs/reference/api/pandas.Series.html\n",
    "\n",
    "A Series is a one-dimensional labeled array capable of holding any data type (integer, float, string, Python objects, etc.). It is similar to a column in a spreadsheet or a SQL table. It consists of two arrays - one for the data and another for the index.\n",
    "\n",
    "The <ins>index</ins> is a sequence of labels that identifies each element in the data array. If an index is not specified, then it is created automatically as a sequence of integers starting from zero.\n",
    "\n",
    "To create a Series, you can pass a Python list, dictionary, or a scalar value as input. For example, to create a Series with a list of integers, you can use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86d9d16-c5ac-4a1f-a52e-7f8b2558bc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = [1, 2, 3, 4, 5]\n",
    "s = pd.Series(data)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b315740-4964-410b-b5ad-a3f6517456a5",
   "metadata": {},
   "source": [
    "In this example, the index is automatically created as a sequence of integers from 0 to 4, and the data is a list of integers.\n",
    "\n",
    "You can access elements in a Series using their index. For example, to access the element at index 2, you can use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe63f482-914a-480d-8a83-4503e1ae0228",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13232a20-b550-4a46-a4f5-42a1fd7221c1",
   "metadata": {},
   "source": [
    "You can also perform operations on a Series, such as arithmetic operations and boolean indexing, just like you would with NumPy arrays.\n",
    "\n",
    "### DataFrame <a name=\"DataFrame\"></a>\n",
    "\n",
    "DataFrame documentation: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html\n",
    "\n",
    "A DataFrame is a two-dimensional labeled data structure, similar to a spreadsheet or a SQL table. It consists of rows and columns, where each column can have a different data type (integer, float, string, etc.). You can think of a DataFrame as a collection of Series that share the same index.\n",
    "\n",
    "To create a DataFrame, you can pass a dictionary of lists, where each key represents a column name, and each value represents the data for that column. For example, to create a DataFrame with three columns, you can use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d149a554-97f7-4136-aba0-97d0706f2c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = {'name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "        'age': [25, 30, 35, 40],\n",
    "        'city': ['New York', 'Paris', 'London', 'Tokyo']}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f8f44b-4294-4e81-a749-1dae5e643e8d",
   "metadata": {},
   "source": [
    "In this example, the keys of the dictionary ('name', 'age', 'city') become the column names, and the values of the dictionary become the data for each column.\n",
    "\n",
    "You can access elements in a DataFrame using various methods such as .loc[], .iloc[], and .at[]. For example, to access the element at row 1 and column 'name', you can use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5937eeb1-8b97-4747-b05c-892c482b39bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.loc[1, 'name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052362a5-dd9c-49fe-8695-30618e9cf794",
   "metadata": {},
   "source": [
    "You can also perform various operations on a DataFrame, such as filtering, grouping, merging, joining, and more. Pandas provides many powerful methods to manipulate data in a DataFrame, making it a popular choice for data analysis in Python.\n",
    "\n",
    "[Return to top](#Start)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfe2048-2b77-4fad-8aa0-2d116d144ded",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Import/Export\n",
    "\n",
    "### Writing data to CSV <a name=\"Write\"></a>\n",
    "\n",
    "to_csv documentation: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html\n",
    "\n",
    "To write data to a CSV file using Pandas in Python, you can use the 'to_csv()' method of a Pandas DataFrame object.\n",
    "\n",
    "Here is an example code snippet that demonstrates how to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d2aa2f-42b1-4817-b5bc-660444e47eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create a sample dataframe\n",
    "data = {'name': ['John', 'Emma', 'Sarah', 'Daniel'],\n",
    "        'age': [25, 27, 29, 31],\n",
    "        'country': ['USA', 'UK', 'Australia', 'Canada']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# write the dataframe to a CSV file\n",
    "df.to_csv('data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3f3227-fd5f-4d7b-969c-bad293106148",
   "metadata": {},
   "source": [
    "In this example, we first create a sample dataframe with some data. We then call the to_csv() method on the dataframe, passing the name of the output file as an argument. The index=False argument tells Pandas not to write the index column to the output file.\n",
    "\n",
    "After running this code, you should find a new file named \"output.csv\" in the current working directory containing the data from the dataframe.\n",
    "\n",
    "[Return to top](#Start)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b59e0b-7bfc-4dba-9a7e-3dfc15834ffb",
   "metadata": {},
   "source": [
    "### Reading data from CSV <a name=\"Read\"></a>\n",
    "\n",
    "read_csv documentation: https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html\n",
    "\n",
    "To import CSV data into a pandas DataFrame, you can use the read_csv() function provided by the pandas library. Here's how to do it:\n",
    "\n",
    "First, import the pandas library using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dbbde9-c87e-4840-bf87-dfc273b7b573",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af4f43e-800b-4596-896e-23e23a088c84",
   "metadata": {},
   "source": [
    "You will only need to include this once. It is included multiple times here to allow you to run individuals parts of the file.\n",
    "\n",
    "Next, use the read_csv() function to load the CSV data into a pandas DataFrame. The syntax for the function is as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0d0870-385d-4c9f-9b3f-145a5163eceb",
   "metadata": {},
   "source": [
    "<b>pd.read_csv('filename.csv')</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccdf4e8-03e9-4bb5-81a5-cdb78e000bea",
   "metadata": {},
   "source": [
    "Replace filename.csv with the path to your CSV file. If your CSV file is in the same directory as your Python script, you can simply specify the filename. Otherwise, you'll need to provide the full path to the file.\n",
    "\n",
    "If the file cannot be found, you will recieve FileNotFoundError: [Errno 2] No such file or directory: 'filename.csv' at the end of the error message output.\n",
    "\n",
    "For example, if you have a CSV file called data.csv in the same directory as your Python script, you can load it into a DataFrame like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba42811-a9d8-4970-8c6d-0576a2159fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114bcab8-f1f9-4aa5-9a3f-7be284f1b8c3",
   "metadata": {},
   "source": [
    "By default, the read_csv() function assumes that the first row of the CSV file contains column headers. \n",
    "\n",
    "If your CSV file doesn't have column headers, you can specify them using the <ins>header</ins> parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a089f79a-f0ca-4d9a-997f-c070930e9d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv', header=None, names=['col1', 'col2', 'col3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd72a455-5f1f-487a-bb34-614b8ce0491a",
   "metadata": {},
   "source": [
    "This will create column headers named 'col1', 'col2', and 'col3' for your DataFrame.\n",
    "\n",
    "There are many other options you can use with the read_csv() function to customize how the CSV data is loaded. \n",
    "\n",
    "You can find more information in the pandas documentation.\n",
    "\n",
    "[Return to top](#Start)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdcc837-a767-415f-a006-b961800e91c1",
   "metadata": {},
   "source": [
    "## Data Manipulation \n",
    "\n",
    "- [Viewing](#View) data.\n",
    "- [Describing](#View) data.\n",
    "- [Selecting](#Select) data.\n",
    "- [Sorting](#Sort) data.\n",
    "- [Filtering](#Filter) data.\n",
    "- [Merging](#Merge) data.\n",
    "- [Grouping](#Group) data.\n",
    "- [Aggregating](#Aggregate) data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be6d61c-b1de-4f65-a378-cb08ebc644a4",
   "metadata": {},
   "source": [
    "### Viewing data <a name=\"View\"></a>\n",
    "\n",
    "head() documentation: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html\n",
    "\n",
    "When first working with a dataset, it is best practice to understand the data you are working with. Many datasets can be quite large and difficult or impossible to open with Excel, Notepad++, etc. becasuse they try to open the entire dataset. The .head() function in Pandas is a method that is used to display the first n rows of a DataFrame or Series. By default, n is 5, which means that the .head() function will display the first 5 rows of the DataFrame or Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fcc0ac-1579-4b91-83e1-0acf7cc3358f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create a sample dataframe\n",
    "data = {'name': ['John', 'Emma', 'Sarah', 'Daniel', 'Raphael', 'Leonardo', 'Michelangelo', 'Mary', 'Vincent', 'Pablo'],\n",
    "        'age': [27, 31, 25, 22, 28, 25, 37, 43, 33, 25],\n",
    "        'country': ['USA', 'UK', 'Australia', 'Canada', 'Italy', 'Italy', 'Italy', 'USA', 'Netherlands', 'Spain']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# display the first rows of the dataframe\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fdfe2a-7529-4930-9805-23c5d42acc6c",
   "metadata": {},
   "source": [
    "In this example, we first create a sample DataFrame df with some data.The .head() function is called on the DataFrame object df, with no argument passed to the function. We can also set the argument to a value to tell the function to display the first n rows of the DataFrame. Below is n=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1195c6-9f69-40e0-a63c-d5fa0f84b89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the first 3 rows of the dataframe\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12cb813-dba2-41dd-8447-7b17a9e6c796",
   "metadata": {},
   "source": [
    "You can use the .head() function to quickly inspect the first few rows of a DataFrame or Series and get a sense of the data. By default, the function displays the first 5 rows, but you can pass a different number to the function to display a different number of rows.\n",
    "\n",
    "Alternatively, you can display the end of the dataset using tail() to display the last n rows of a DataFrame or Series. By default, n is 5, which means that the .tail() function will display the last 5 rows of the DataFrame or Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8928c3b-a2b9-4be6-b09e-bd7ceed83645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the last 3 rows of the dataframe\n",
    "print(df.tail(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab59e2a-b275-43d5-850b-a31c69b46af3",
   "metadata": {},
   "source": [
    "[Return to top](#Start)\n",
    "***\n",
    "\n",
    "### Describing data <a name=\"Describe\"></a>\n",
    "\n",
    "describe() documentation: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html\n",
    "\n",
    "The describe() function is a useful method in the Pandas library for quickly generating descriptive statistics of a DataFrame or a specific column in a DataFrame.\n",
    "\n",
    "When applied to a DataFrame, describe() returns a summary of statistics for each <ins>numeric</ins> column in the DataFrame such as count, mean, standard deviation, minimum, maximum, and the quartile values. When applied to a non-numeric column, it will return the count, number of unique values, top, and frequency of the top value.\n",
    "\n",
    "The statistics that are included in the output of the describe() function are:\n",
    "- count: the number of non-missing values in each column.\n",
    "- mean: the arithmetic mean (average) of the values in each column.\n",
    "- std: the standard deviation of the values in each column.\n",
    "- min: the minimum value in each column.\n",
    "- 25%: the 25th percentile value in each column.\n",
    "- 50%: the median value (50th percentile) in each column.\n",
    "- 75%: the 75th percentile value in each column.\n",
    "- max: the maximum value in each column.\n",
    "\n",
    "It is important to note that the describe() function only generates statistics for the columns with numeric data types by default. However, if you set the include parameter to 'all', it will include summary statistics for both numeric and non-numeric columns.\n",
    "\n",
    "Here is an example of how to use the describe() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997d9140-f9a2-4b49-ab66-af3099dffb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame with some sample data\n",
    "data = {'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Emily'],\n",
    "        'Age': [25, 30, 35, 40, 45],\n",
    "        'Salary': [50000, 60000, 70000, 80000, 90000]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Call the describe() function on the DataFrame\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad787c1b-e323-4a44-82f2-3d375b8b4385",
   "metadata": {},
   "source": [
    "From the output, we can see that the describe() function has generated summary statistics for the numeric columns Age and Salary in the DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dda6db8-1ed2-47ae-a04a-31949f20fd48",
   "metadata": {},
   "source": [
    "[Return to top](#Start)\n",
    "***\n",
    "\n",
    "### Selecting data <a name=\"Select\"></a>\n",
    "\n",
    "loc() documentation: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html\n",
    "\n",
    "iloc() documentation: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iloc.html\n",
    "\n",
    "\n",
    "### loc()\n",
    "\n",
    "The .loc() function in Pandas is a method that is used to access a group of rows and columns in a DataFrame by label(s) or a boolean array. It allows you to subset or filter your data based on a specific row or column label or a specific condition.\n",
    "\n",
    "The general syntax for using the .loc() function is as follows:\n",
    "\n",
    "df.loc[row_labels, column_labels]\n",
    "\n",
    "where df is the DataFrame you want to access, row_labels is the label or a boolean array for selecting specific rows, and column_labels is the label or a list of labels for selecting specific columns. The .loc() function takes two arguments: the first one specifies the row label, and the second one specifies the column label. <b>You can use a colon to select a range of labels</b>. For example, if you want to select all rows and some specific columns, you can use .loc[:, ['column1', 'column2']].\n",
    "\n",
    "Here are some examples of how to use the .loc() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6c0d7c-b876-485e-8199-f260f9f960dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create a sample dataframe\n",
    "data = {'name': ['John', 'Emma', 'Sarah', 'Daniel', 'Raphael', 'Leonardo', 'Michelangelo', 'Mary', 'Vincent', 'Pablo'],\n",
    "        'age': [27, 31, 25, 22, 28, 25, 37, 43, 33, 25],\n",
    "        'country': ['USA', 'UK', 'Australia', 'Canada', 'Italy', 'Italy', 'Italy', 'USA', 'Netherlands', 'Spain']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# access the row with index label 2\n",
    "print(df.loc[2])\n",
    "print('\\n')\n",
    "\n",
    "# access the row with index labels 1, 3, and 5\n",
    "print(df.loc[[1, 3, 5]])\n",
    "print('\\n')\n",
    "\n",
    "# access the rows with boolean array\n",
    "print(df.loc[df['age'] > 28])\n",
    "print('\\n')\n",
    "\n",
    "# access the rows and columns with label or list of labels\n",
    "print(df.loc[[1, 3, 5], ['name', 'country']])\n",
    "print('\\n')\n",
    "\n",
    "# access all the rows in specific columns with label or list of labels\n",
    "print(df.loc[:, ['name']])\n",
    "print('\\n')\n",
    "\n",
    "# access a specific slice of rows (rows 2-4) and all columns\n",
    "print(df.loc[2:4, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b1de83-c599-4501-bbb3-9657b6261a21",
   "metadata": {},
   "source": [
    "The .loc() function is useful when you need to select data from a DataFrame based on the label or index of the rows and columns. It is an efficient way to retrieve specific data from a DataFrame without having to iterate over the entire DataFrame.\n",
    "\n",
    "\n",
    "### iloc()\n",
    "\n",
    "iloc() documentation: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iloc.html\n",
    "\n",
    "The .iloc() function in Pandas is an integer-based indexing method used to select rows and columns from a DataFrame. It is used to retrieve data from a Pandas DataFrame based on the position or index of the rows and columns.\n",
    "\n",
    "The .iloc() function takes two arguments: the first one specifies the row position, and the second one specifies the column position. You can use a colon to select a range of positions. For example, if you want to select all rows and some specific columns, you can use .iloc[:, [0, 1, 2]].\n",
    "\n",
    "Here's an example of how to use the .iloc() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1db462-25bf-4fc8-a0d6-fd87bf74bcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create a sample dataframe\n",
    "data = {'name': ['John', 'Emma', 'Sarah', 'Daniel', 'Raphael', 'Leonardo', 'Michelangelo', 'Mary', 'Vincent', 'Pablo'],\n",
    "        'age': [27, 31, 25, 22, 28, 25, 37, 43, 33, 25],\n",
    "        'country': ['USA', 'UK', 'Australia', 'Canada', 'Italy', 'Italy', 'Italy', 'USA', 'Netherlands', 'Spain']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# select the row at position 2 and the column at position 3\n",
    "print(df.iloc[2, 2])\n",
    "print('\\n')\n",
    "\n",
    "# select the rows at positions 1 through 3 and all columns\n",
    "print(df.iloc[1:4, :])\n",
    "print('\\n')\n",
    "\n",
    "# select the rows at positions 0, 2, and 4 and the columns at positions 0 and 2\n",
    "print(df.iloc[[0, 2, 4], [0, 2]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eed0836-d36a-4265-a821-1d82b48048e9",
   "metadata": {},
   "source": [
    "[Return to top](#Start)\n",
    "***\n",
    "\n",
    "### Sorting <a name=\"Sort\"></a>\n",
    "\n",
    "sort_values() documentation: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_values.html\n",
    "\n",
    "sort_index() documentation: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_index.html\n",
    "\n",
    "You can sort the data in a Pandas DataFrame using the 'sort_values()' method. The 'sort_values()' method sorts a DataFrame by one or more columns.\n",
    "\n",
    "Here's an example code that demonstrates how to sort a DataFrame by a single column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf338408-384b-4c53-a7e5-6639d5182c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create a sample dataframe\n",
    "data = {'name': ['John', 'Emma', 'Sarah', 'Daniel', 'Raphael', 'Leonardo', 'Michelangelo', 'Mary', 'Vincent', 'Pablo'],\n",
    "        'age': [27, 31, 25, 22, 28, 25, 37, 43, 33, 25],\n",
    "        'country': ['USA', 'UK', 'Australia', 'Canada', 'Italy', 'Italy', 'Italy', 'USA', 'Netherlands', 'Spain']}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Original DataFrame\")\n",
    "print(df) # display the unsorted dataframe\n",
    "\n",
    "# sort the dataframe by the 'age' column in ascending order\n",
    "df = df.sort_values(by='age', ascending=True)\n",
    "\n",
    "# display the sorted dataframe\n",
    "print(\"\\n\",\"DataFrame sorted by 'Age' column\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4ecae6-2eae-4acc-afa1-c715eb3e174e",
   "metadata": {},
   "source": [
    "In this example, we first create a sample DataFrame with some data. We then call the sort_values() method on the DataFrame, passing the name of the column to sort by as an argument (in this case, \"age\"). By default, 'sort_values()' sorts in ascending order, so we don't need to pass the ascending argument. If we wanted to sort in descending order, we could pass ascending=False as an argument.\n",
    "\n",
    "After running this code, the DataFrame will be sorted by the \"age\" column in ascending order, and the sorted DataFrame will be displayed.\n",
    "\n",
    "You can also sort a DataFrame by multiple columns by passing a list of column names to the by argument of the 'sort_values()' method. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af034b8-298e-46fc-b7cd-27c6729d7410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the dataframe by the 'country' column in ascending order,\n",
    "# and then by the 'age' column in descending order\n",
    "df = df.sort_values(by=['country', 'age'], ascending=[True, False])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6db05a7-cc7e-4658-b8c8-9c04d53eb079",
   "metadata": {},
   "source": [
    "In this case, the DataFrame will be first sorted by the \"country\" column in ascending order, and then by the \"age\" column in descending order.\n",
    "\n",
    "Note that the index column still has the original order preserved after using 'sort_values()'. This can be helpful if you want to put the data back in the original order using 'sort_index()'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33095645-dd18-4ee9-a36b-6a40d6031b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.sort_index()) # reorder the DataFrame by index and print the result\n",
    "\n",
    "# note that we did not save the DataFrame this time. Try to use print(df) and check the output here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e8464c-aacb-4e03-8f07-a3f4481492be",
   "metadata": {},
   "source": [
    "You can also reset the index to the new order by using 'reset_index()' with the drop=True argument, which removes the original index column and replaces it with a new range index starting from 0. Setting drop=False will preserve the origial index in a new column named 'index' while also renumbering the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328a631e-554a-4021-9ec8-448649bc01ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by='name', ascending=True)\n",
    "print(\"Current DataFrame\")\n",
    "print(df)\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "print(\"\\n\",\"DataFrame sorted by 'Name' column\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91a3dd2-01fb-4502-9192-b8aba17aa2ec",
   "metadata": {},
   "source": [
    "[Return to top](#Start)\n",
    "***\n",
    "\n",
    "### Filtering Data <a name=\"Filter\"></a>\n",
    "\n",
    "You can filter data in a Pandas DataFrame using one or more conditional arguments. For example, if you wanted to select all members of our DataFrame based on Age, we could select only those over 25 using the conditional statement below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c6417d-5d82-4873-9144-d31a0298a5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create a sample dataframe\n",
    "data = {'name': ['John', 'Emma', 'Sarah', 'Daniel', 'Raphael', 'Leonardo', 'Michelangelo', 'Mary', 'Vincent', 'Pablo'],\n",
    "        'age': [27, 31, 25, 22, 28, 25, 37, 43, 33, 25],\n",
    "        'country': ['USA', 'UK', 'Australia', 'Canada', 'Italy', 'Italy', 'Italy', 'USA', 'Netherlands', 'Spain']}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Original DataFrame\")\n",
    "print(df) # display the unsorted dataframe\n",
    "\n",
    "# filter the dataframe by the condition where age is greater than 25\n",
    "filtered_df = df[df['age'] > 25]\n",
    "\n",
    "# display the filtered dataframe\n",
    "print(\"\\n\",\"Filtered DataFrame\")\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510830b5-6e6a-446c-84ad-cf405575b100",
   "metadata": {},
   "source": [
    "In this example, we first create a sample DataFrame with some data. We then filtered the DataFrame based on the condition where age is greater than 25 and assigned that output to a new DataFrame called 'filtered_df'.\n",
    "\n",
    "The df['age'] > 25 part of this code creates a boolean array with True or False values depending on whether each row satisfies the condition. The df[df['age'] > 25] part of the code selects only the rows where the condition is True.\n",
    "\n",
    "We can see the generated boolean array below. Only the values that met the condition and are marked as True will be passed to filtered_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f00be77-1003-471b-919d-6b7b8f02ee76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'] > 25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6c81fb-8445-4ffe-83cd-f190bfdbbf32",
   "metadata": {},
   "source": [
    "After running this code, the filtered DataFrame will contain only the rows where the age is greater than 25, and the filtered DataFrame will be displayed.\n",
    "\n",
    "You can also combine multiple conditions using logical operators such as & (and) and | (or) as well as using non-numeric filters such as names or countries. For example let's filter to only anyone over the age of 25 and is from either USA or Italy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4da0bf1-e3b8-4349-ab96-a0c64bd59778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the dataframe by the condition where age is greater than 25\n",
    "# and country is either USA or Canada\n",
    "filtered_df = df[(df['age'] > 25) & ((df['country'] == 'USA') | (df['country'] == 'Italy'))]\n",
    "\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1db3b93-1dbd-4e39-8cf1-56da855b5ee5",
   "metadata": {},
   "source": [
    "In this case, the filtered DataFrame will contain only the rows where the age is greater than 25 and the country is either \"USA\" or \"Italy\".\n",
    "\n",
    "Other methods of filtering include using 'query()'.\n",
    "\n",
    "[Return to top](#Start)\n",
    "***\n",
    "\n",
    "## Merging Data <a name=\"Merge\"></a>\n",
    "\n",
    "In Pandas, you can merge two or more DataFrames into a single DataFrame based on one or more common columns. This is similar to the SQL JOIN operation. Pandas provides various methods for easily combining together Series or DataFrame with various kinds of set logic for the indexes and relational algebra functionality in the case of join / merge-type operations.\n",
    "\n",
    "In addition, pandas also provides utilities to compare two Series or DataFrame and summarize their differences.\n",
    "\n",
    "For a great overview with visuals, check out the Merge, Join, Concatenate, and Compare functions documentation page: https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html\n",
    "\n",
    "### merge()\n",
    "\n",
    "merge documentation: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.merge.html\n",
    "\n",
    "The merge() function in Pandas can be used to merge two DataFrames <ins>based on the values within one or more columns</ins>. Here's an example that demonstrates how to merge two DataFrames based on a common column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1212ffbb-0e97-4279-8963-61c76490a82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create a sample dataframe1\n",
    "data1 = {'name': ['John', 'Emma', 'Sarah', 'Daniel'],\n",
    "        'age': [25, 27, 29, 31],\n",
    "        'country': ['USA', 'UK', 'Australia', 'Canada']}\n",
    "df1 = pd.DataFrame(data1)\n",
    "print(\"DataFrame #1\")\n",
    "print(df1)\n",
    "\n",
    "# create a sample dataframe2\n",
    "data2 = {'name': ['John', 'Emma', 'Sarah', 'Daniel'],\n",
    "        'salary': [50000, 60000, 70000, 80000]}\n",
    "df2 = pd.DataFrame(data2)\n",
    "print(\"\\n\",\"DataFrame #2\")\n",
    "print(df2)\n",
    "\n",
    "# merge the two dataframes based on the 'name' column\n",
    "merged_df = pd.merge(df1, df2, on='name')\n",
    "\n",
    "# display the merged dataframe\n",
    "print(\"\\n\",\"Merged DataFrame\")\n",
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d35a8d-f1ae-40f1-a877-31cd343fdb0f",
   "metadata": {},
   "source": [
    "In this example, we first create two sample DataFrames with some data. The first DataFrame df1 contains columns for name, age, and country, while the second DataFrame df2 contains columns for name and salary. We then use the following line of code to merge the two DataFrames based on the 'name' column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f85329a-2771-4515-8bfb-b01e8fe315e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(df1, df2, on='name')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311c51a7-0ce1-4fe7-8879-4d709cce8f38",
   "metadata": {},
   "source": [
    "The on='name' part of this code specifies that we want to merge the two DataFrames based on the 'name' column. By default, merge() performs an inner join, which means that only the rows with matching values in both DataFrames will be included in the merged DataFrame.\n",
    "\n",
    "After running this code, the merged DataFrame will contain all the columns from both DataFrames and will be displayed.\n",
    "\n",
    "You can also merge DataFrames based on multiple columns by passing a list of column names to the on argument. Additionally, you can specify different types of joins using the how argument, such as \"left\", \"right\", \"outer\", and \"inner\". For more information on merging DataFrames in Pandas, refer to the official documentation.\n",
    "***\n",
    "\n",
    "### concat()\n",
    "\n",
    "concat documentation: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html\n",
    "\n",
    "In Pandas, the concat() function is used to concatenate two or more DataFrames <ins>along a particular axis</ins> (either rows or columns). The concat() function can be used to combine DataFrames even if they have different shapes, column names, and indexes.\n",
    "\n",
    "Here's an example that demonstrates how to use the concat() function to concatenate two DataFrames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef415c2c-a49c-4131-b851-c5843197557f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create a sample dataframe1\n",
    "data1 = {'name': ['John', 'Emma', 'Sarah', 'Daniel'],\n",
    "        'age': [25, 27, 29, 31]}\n",
    "df1 = pd.DataFrame(data1)\n",
    "print(\"DataFrame #1\")\n",
    "print(df1)\n",
    "\n",
    "# create a sample dataframe2\n",
    "data2 = {'name': ['Olivia', 'Sophia', 'Ethan', 'Liam'],\n",
    "        'age': [24, 26, 28, 30]}\n",
    "df2 = pd.DataFrame(data2)\n",
    "print(\"\\n\",\"DataFrame #2\")\n",
    "print(df2)\n",
    "\n",
    "# concatenate the two dataframes along rows\n",
    "concatenated_df = pd.concat([df1, df2])\n",
    "\n",
    "# display the concatenated dataframe\n",
    "print(\"\\n\",\"Concatenated DataFrame\")\n",
    "print(concatenated_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6681b9-a74a-4ffe-a140-82b1e7f55d3a",
   "metadata": {},
   "source": [
    "In this example, we first create two sample DataFrames with some data. The first DataFrame df1 contains columns for name and age, while the second DataFrame df2 contains columns for name and age. We then use the following line of code to concatenate the two DataFrames along the rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1b5964-e5d2-4ced-9b65-c548cb3ce700",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_df = pd.concat([df1, df2])\n",
    "print(concatenated_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def7709b-ebaa-48bc-9974-a878dfe8bb12",
   "metadata": {},
   "source": [
    "The pd.concat() function is passed a list of DataFrames to concatenate. By default, the function concatenates the DataFrames along the rows (axis=0). If you want to concatenate the DataFrames along the columns (axis=1), you can specify the axis argument as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70cca0f-ba81-47fc-b0aa-eb570b67f6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_df = pd.concat([df1, df2], axis=1)\n",
    "print(concatenated_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdefe1fd-8456-48e7-843f-33fc7f3d7c9e",
   "metadata": {},
   "source": [
    "After running this code, the concatenated DataFrame will contain all the rows from both DataFrames and will be displayed. If the two DataFrames have different columns, the resulting concatenated DataFrame will have all the columns from both DataFrames, with missing values (NaN) in the cells where data is missing.\n",
    "\n",
    "Take note of the index in both cases. When using concat along the rows (axis=0), there are now multiple index entries that have the same value. You can also specify how the indexes should be handled when concatenating DataFrames using the ignore_index argument. If ignore_index=True, the resulting concatenated DataFrame will have a new index that ignores the original indexes of the input DataFrames. If ignore_index=False (the default), the original indexes of the input DataFrames will be preserved in the resulting concatenated DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fbb2d2-21f6-46c7-a26c-6c516f3dcf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_df = pd.concat([df1, df2], ignore_index=True)\n",
    "print(concatenated_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d67432-aa7b-41ea-975f-a9c6d9b4b388",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### join()\n",
    "\n",
    "join documentation: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.join.html\n",
    "\n",
    "The join() function is used to join two or more DataFrames <ins>based on the indexes or columns of the DataFrames</ins>. The join() function is similar to the merge() function, but it is a convenient method for combining DataFrames that have the same or similar indexes.\n",
    "\n",
    "Here's an example that demonstrates how to use the join() function to join two DataFrames based on their indexes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6b7064-f078-4a2f-927e-5a1f38c0d797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a sample dataframe1 containing age and using names as the index values\n",
    "data1 = {'age': [25, 27, 29, 31]}\n",
    "df1 = pd.DataFrame(data1, index=['John', 'Emma', 'Sarah', 'Daniel']) # here we assign the index to be names\n",
    "print(\"DataFrame #1\")\n",
    "print(df1)\n",
    "\n",
    "# create a sample dataframe2\n",
    "data2 = {'salary': [50000, 60000, 70000, 80000]}\n",
    "df2 = pd.DataFrame(data2, index=['John', 'Emma', 'Sarah', 'Daniel']) # here we assign the index to be the same names\n",
    "print(\"\\n\",\"DataFrame #2\")\n",
    "print(df2)\n",
    "\n",
    "# join the two dataframes based on their indexes\n",
    "joined_df = df1.join(df2)\n",
    "\n",
    "# display the joined dataframe\n",
    "print(\"\\n\",\"Joined DataFrame\")\n",
    "print(joined_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2ebb4b-a90f-40dd-8d81-71c1bb66e625",
   "metadata": {},
   "source": [
    "In this example, we first create two sample DataFrames with some data. The first DataFrame df1 contains a column for age and has the same index as the second DataFrame df2. The second DataFrame df2 contains a column for salary. We then use the following line of code to join the two DataFrames based on their indexes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d41fc6-31ad-4439-a122-4dac88074863",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = df1.join(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf3496a-038b-4393-a5ff-9a8857e36c0e",
   "metadata": {},
   "source": [
    "The join() function is called on the first DataFrame, and the second DataFrame is passed as an argument to the function. By default, the join() function performs a left join, which means that all the rows from the first DataFrame are included in the resulting DataFrame, and only the matching rows from the second DataFrame are included. If there are missing values in the second DataFrame, the cells will be filled with NaN.\n",
    "\n",
    "After running this code, the joined DataFrame will contain all the columns from both DataFrames and will be displayed.\n",
    "\n",
    "You can also specify how to join the DataFrames using the how argument. For example, you can perform an inner join, outer join, or right join by specifying how='inner', how='outer', or how='right', respectively. You can also join the DataFrames based on their columns instead of their indexes by specifying the column names using the on argument.\n",
    "***\n",
    "\n",
    "### compare()\n",
    "\n",
    "compare documentation: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.compare.html\n",
    "\n",
    "The compare() function is used to compare two DataFrames or two Series and returns a DataFrame of Boolean values indicating whether the corresponding elements in the two DataFrames or Series are equal or not.\n",
    "\n",
    "Here's an example code snippet that demonstrates how to use the compare() function to compare two DataFrames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857c7dff-30a3-4fcc-a411-4a995f75bf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create two sample dataframes\n",
    "data1 = {'name': ['John', 'Emma', 'Sarah', 'Daniel'],\n",
    "        'age': [25, 27, 29, 31]}\n",
    "df1 = pd.DataFrame(data1)\n",
    "print(\"DataFrame #1\")\n",
    "print(df1)\n",
    "\n",
    "data2 = {'name': ['John', 'Emma', 'Sarah', 'David'],\n",
    "        'age': [25, 27, 29, 31]}\n",
    "df2 = pd.DataFrame(data2)\n",
    "print(\"\\n\",\"DataFrame #2\")\n",
    "print(df2)\n",
    "\n",
    "# compare the two dataframes\n",
    "compared_df = df1.compare(df2)\n",
    "\n",
    "# display the compared dataframe\n",
    "print(\"\\n\",\"Differences between the two\")\n",
    "print(compared_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14401352-a7cb-4049-b2d8-eca955d9f5b5",
   "metadata": {},
   "source": [
    "In this example, we first create two sample DataFrames with some data. The first DataFrame df1 contains columns for name and age, while the second DataFrame df2 contains columns for name and age but with a different name \"David\" instead of \"Daniel\". We then use the following line of code to compare the two DataFrames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387540ab-457b-4b73-af9b-05982f6e309a",
   "metadata": {},
   "outputs": [],
   "source": [
    "compared_df = df1.compare(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8479028-a99c-45a7-a22b-fda3cfdd3bdb",
   "metadata": {},
   "source": [
    "The compare() function is called on the first DataFrame, and the second DataFrame is passed as an argument to the function. By default, the compare() function compares the two DataFrames element-wise and returns a new DataFrame containing Boolean values indicating whether the corresponding elements are equal or not.\n",
    "\n",
    "After running this code, the compared DataFrame will contain the same number of rows and columns as the input DataFrames, and the cells will contain True if the corresponding element in df1 is equal to the corresponding element in df2 and False otherwise. In the output above, the self=df1 and other=df2 based on how we used them in the function.\n",
    "\n",
    "You can also specify how to compare the DataFrames using the method argument. For example, you can compare the DataFrames based on their indexes or columns by specifying method='index' or method='columns', respectively. You can also specify how to handle missing values using the keep_shape and keep_equal arguments.\n",
    "\n",
    "[Return to top](#Start)\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774632da-439d-41da-982a-cc11c11aaea7",
   "metadata": {},
   "source": [
    "## Grouping data <a name=\"Group\"></a>\n",
    "\n",
    "### groupby()\n",
    "groupby() documentation: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html\n",
    "\n",
    "In Pandas, grouping data is the process of splitting data into groups based on some criteria, optionally applying a function to each group independently, and optionally combining the results back into a single DataFrame. The groupby() function is used to group data in Pandas.\n",
    "\n",
    "Here's an example code snippet that demonstrates how to use the groupby() function to group data in a Pandas DataFrame:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700be9d0-cb7d-4a00-836c-94ffefd76a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create a sample dataframe\n",
    "data = {'name': ['John', 'Emma', 'Sarah', 'Daniel', 'Jessica', 'Tom'],\n",
    "        'age': [25, 27, 29, 31, 22, 28],\n",
    "        'state': ['SC', 'SC', 'NC', 'NC', 'SC', 'NC'],\n",
    "        'salary': [50000, 65000, 75000, 80000, 55000, 65000]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "\n",
    "# group the dataframe by state\n",
    "grouped_df = df.groupby(['state'])\n",
    "\n",
    "# calculate the mean salary for each group\n",
    "mean_salary = grouped_df['salary'].mean()\n",
    "\n",
    "# display the mean salary for each group\n",
    "print(\"\\n\",\"Mean Salary by State\")\n",
    "print(mean_salary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87403d40-5e85-4662-ae81-65208c387575",
   "metadata": {},
   "source": [
    "In this example, we first create a sample DataFrame df with some data. The DataFrame contains columns for name, age, state, and salary. We then use the following line of code to group the DataFrame by state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354931c8-a336-4267-9de6-fe39cdf71b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = df.groupby(['state'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b979b8-9a1e-4ae4-8f22-de1ab0e36c3e",
   "metadata": {},
   "source": [
    "The groupby() function is called on the DataFrame, and the column name 'state' is passed as an argument to the function. This creates a DataFrameGroupBy object that contains the original DataFrame split into groups based on the values in the 'state' column.\n",
    "\n",
    "After grouping the DataFrame, we use the following line of code to calculate the mean salary for each group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb19079-dad5-4ae6-897c-e2d3bb219d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_salary = grouped_df['salary'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107ed497-6929-447c-939a-4cc201f167c5",
   "metadata": {},
   "source": [
    "The mean() function is called on the 'salary' column of the DataFrameGroupBy object, which calculates the mean salary for each group. This creates a new Series object containing the mean salary for each group.\n",
    "\n",
    "You can also apply other aggregation functions to each group, such as sum(), count(), min(), max(), and median(). You can also group the DataFrame by multiple columns by passing a list of column names to the groupby() function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe336f26-0b37-41e6-8677-5b796dd54383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate and display the sum of salary for each group\n",
    "sum_salary = grouped_df['salary'].sum()\n",
    "print(\"\\n\",\"Sum of Salary by State\")\n",
    "print(sum_salary)\n",
    "\n",
    "# calculate and display the count of salary for each group\n",
    "count_salary = grouped_df['salary'].count()\n",
    "print(\"\\n\",\"Count of Salary by State\")\n",
    "print(count_salary)\n",
    "\n",
    "# calculate and display the min salary for each group\n",
    "min_salary = grouped_df['salary'].min()\n",
    "print(\"\\n\",\"Min Salary by State\")\n",
    "print(min_salary)\n",
    "\n",
    "# calculate and display the max salary for each group\n",
    "max_salary = grouped_df['salary'].max()\n",
    "print(\"\\n\",\"Max Salary by State\")\n",
    "print(max_salary)\n",
    "\n",
    "# calculate and display the median salary for each group\n",
    "med_salary = grouped_df['salary'].median()\n",
    "print(\"\\n\",\"Median Salary by State\")\n",
    "print(med_salary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7c73de-27ba-422c-808b-2896c955799d",
   "metadata": {},
   "source": [
    "Each group can also be accessed individually as well. In Pandas, the get_group() function is used to retrieve a single group of data from a grouped DataFrame. This function is applied on a GroupBy object, which is created by grouping a DataFrame with one or more columns.\n",
    "\n",
    "### get_group()\n",
    "\n",
    "get_group documentation: https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.GroupBy.get_group.html\n",
    "\n",
    "Here's an example code snippet that demonstrates how to use the get_group() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8022eb-3e5f-4461-87bf-79861e7c3fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create a sample dataframe\n",
    "data = {'name': ['John', 'Emma', 'Sarah', 'Daniel', 'Jessica', 'Tom'],\n",
    "        'age': [25, 27, 29, 31, 22, 28],\n",
    "        'state': ['SC', 'SC', 'NC', 'NC', 'SC', 'NC'],\n",
    "        'salary': [50000, 65000, 75000, 80000, 55000, 65000]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# group the dataframe by state\n",
    "grouped_df = df.groupby(['state'])\n",
    "\n",
    "# get the group of data for the 'SC' state\n",
    "m_group = grouped_df.get_group('SC')\n",
    "\n",
    "# display the group of data for the 'SC' state\n",
    "print(m_group)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579b58d4-c6ef-42ae-b1fb-673af849b280",
   "metadata": {},
   "source": [
    "The groupby() function is called on the DataFrame, and the column name 'state' is passed as an argument to the function. This creates a DataFrameGroupBy object that contains the original DataFrame split into groups based on the values in the 'state' column.\n",
    "\n",
    "After grouping the DataFrame, we use the following line of code to retrieve the group of data for the 'SC' state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5130eb2c-8ab4-4b66-933f-364d65fffc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_group = grouped_df.get_group('SC')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdae308-02e1-41bf-a204-cdd23d80177b",
   "metadata": {},
   "source": [
    "The get_group() function is called on the DataFrameGroupBy object, with the value 'SC' passed as an argument to the function. This creates a new DataFrame object that contains only the rows of the original DataFrame where the state column has the value 'SC'.\n",
    "\n",
    "You can use the get_group() function to retrieve a single group of data based on the values in any column that was used to group the original DataFrame. You can also apply other functions to the group of data, such as filtering or aggregation functions. For more information on the get_group() function and other functions related to grouping data in Pandas, refer to the official documentation.\n",
    "\n",
    "[Return to top](#Start)\n",
    "***\n",
    "\n",
    "## Aggregating data <a name=\"Aggregate\"></a>\n",
    "\n",
    "Aggregating data in pandas refers to the process of grouping and summarizing data based on certain criteria. It is a powerful feature of pandas that allows you to calculate summary statistics, apply functions to subsets of data, and generate pivot tables. Grouping, covered above, is one common method. Two other are aggregating and using pivot tables. \n",
    "\n",
    "### agg()\n",
    "\n",
    "agg documentation: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.agg.html\n",
    "\n",
    "Once you've grouped your data, you can apply aggregate functions to each group using the agg() function. This function takes a dictionary of column names and aggregate functions as input. For example, you can calculate the sum, mean, and count of a column for each group. Similar to what we did after grouping with separate function, can be easily tabulated with agg()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8c34c6-f593-415f-95da-3d93c5d1947a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create a sample dataframe\n",
    "data = {'column_name': ['A', 'A', 'B', 'B', 'B', 'C'],\n",
    "    'column1': [1, 1, 3, 3, 5, 7],\n",
    "    'column2': [2, 2, 4, 4, 6, 8],\n",
    "    'column3': [10.1, 20.2, 30.3, 40.4, 50.5, 60.6]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# group the dataframe by column_name\n",
    "grouped_df = df.groupby(['column_name'])\n",
    "\n",
    "grouped_df.agg({'column1': 'sum', 'column2': 'mean', 'column3': 'count'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10710258-7076-4071-83a4-f0b8906aa445",
   "metadata": {},
   "source": [
    "In this example, the data has four columns: column_name, column1, column2, and column3. The values in column_name are either 'A', 'B', or 'C', and the values in column1 and column2 are integers. The values in column3 are numeric and represent some kind of data that you want to analyze.\n",
    "\n",
    "As you can see, the grouped.agg() function groups the data by the values in column_name and calculates the sum of column1, mean of column2, and count of column3 for each group. This provides a useful summary of the data that can be used for further analysis or visualization.\n",
    "\n",
    "[Return to top](#Start)\n",
    "***\n",
    "\n",
    "### pivot_table()\n",
    "\n",
    "pivot_table documentation: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pivot_table.html\n",
    "\n",
    "Pivot tables are a powerful tool for summarizing and analyzing data. They create a spreadsheet-style pivot table that summarizes and aggregates data in a DataFrame. This function allows you to group data by one or more columns, apply a function to one or more columns of values, and reshape the results into a new DataFrame with a hierarchical index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0a2d3f-9f0e-4d8e-8fc7-e5c72e1f90ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create a sample dataframe\n",
    "data = {'column1': ['A', 'A', 'B', 'B', 'B', 'C', 'C', 'C', 'C'],\n",
    "    'column2': [1, 2, 1, 2, 2, 1, 2, 1, 1],\n",
    "    'column3': [10.1, 20.2, 30.3, 40.4, 50.5, 60.6, 70.7, 80.8, 90.9]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "pivot_table = pd.pivot_table(df, index=['column1', 'column2'], values='column3', aggfunc='sum')\n",
    "print(pivot_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7e0b3e-5e07-4a7d-b52a-3106f9c5dc63",
   "metadata": {},
   "source": [
    "This will create a pivot table that groups the data by the columns 'column1' first and then 'column2' and calculates the sum of 'column3' for each group. As you can see, the pivot table groups the data by the values in column1 and column2 and calculates the sum of column3 for each group. This provides a useful summary of the data that can be used for further analysis or visualization.\n",
    "\n",
    "Here's the basic syntax of the pivot_table() function:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6bb3bd-bd93-4bf2-839a-e0ccc37c6ee8",
   "metadata": {},
   "source": [
    "<b>pivot_table(data, values=None, index=None, columns=None, aggfunc='mean', fill_value=None, margins=False, dropna=True, margins_name='All')</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1491f4e8-1c28-4f1f-a608-01d1c327ccb8",
   "metadata": {},
   "source": [
    "The parameters of this function are:\n",
    "\n",
    "- <b>data</b>: This is the DataFrame that you want to use to create the pivot table.\n",
    "values: This is the column or list of columns that you want to apply the aggregation function to.\n",
    "- <b>index</b>: This is the column or list of columns that you want to group the data by.\n",
    "columns: This is the column or list of columns that you want to use as the columns in the pivot table.\n",
    "- <b>aggfunc</b>: This is the aggregation function that you want to apply to the values column or columns. The default is mean, but you can use other functions like sum, min, max, count, std, var, and so on.\n",
    "- <b>fill_value</b>: This is the value that you want to use to replace missing values in the pivot table. The default is None.\n",
    "- <b>margins</b>: This is a Boolean value that indicates whether to include row and column totals in the pivot table. The default is False.\n",
    "- <b>dropna</b>: This is a Boolean value that indicates whether to exclude rows or columns from the pivot table that contain missing values. The default is True.\n",
    "- <b>margins_name</b>: This is the name that you want to use for the row and column totals in the pivot table. The default is 'All'.\n",
    "\n",
    "[Return to top](#Start)\n",
    "***\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35a8cb6-888e-4752-8971-10106c65f042",
   "metadata": {},
   "source": [
    "## Plotting data basics <a name=\"Plot\"></a>\n",
    "\n",
    "The plot function in the Python Pandas library is used to create different types of plots such as line plots, bar plots, histogram plots, scatter plots, and many others. This function is applied on a Pandas DataFrame or Series to visualize the data in a graphical format.\n",
    "\n",
    "The plot function has several parameters that can be used to customize the appearance and behavior of the plot. Some of the most commonly used parameters are:\n",
    "\n",
    "- kind: This parameter specifies the type of plot to be created. The available options include line, bar, histogram, scatter, and many others.\n",
    "- x and y: These parameters specify the column names or indices to be plotted on the x and y-axes, respectively.\n",
    "- title: This parameter is used to set the title of the plot.\n",
    "- xlabel and ylabel: These parameters are used to set the labels for the x and y-axes.\n",
    "- color: This parameter is used to specify the color of the plot.\n",
    "- legend: This parameter is used to display the legend on the plot.\n",
    "\n",
    "A great reference for ideas and code for plotting: https://pandas.pydata.org/docs/user_guide/visualization.html\n",
    "\n",
    "Here is an example of how to use the plot function to create a line plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20a3427-2ec7-4645-91bc-bceb817473ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a sample DataFrame\n",
    "data = pd.DataFrame({'x': np.arange(10),\n",
    "                     'y': np.random.randn(10)})\n",
    "\n",
    "# Plot the data as a line plot\n",
    "data.plot(x='x', y='y', kind='line')\n",
    "\n",
    "# Add title and axis labels\n",
    "plt.title('Sample Line Plot')\n",
    "plt.xlabel('X-axis')\n",
    "plt.ylabel('Y-axis')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f2e397-eff4-4d68-aa74-3a8bb9fbe19f",
   "metadata": {},
   "source": [
    "This code will create a line plot of the data in the DataFrame, with the x-axis showing the values of the 'x' column and the y-axis showing the values of the 'y' column. The plot will also have a title and axis labels.\n",
    "\n",
    "In addition to creating basic line plots, bar plots, and scatter plots, the plot function in Pandas provides many customization options and supports many other types of plots such as:\n",
    "\n",
    "- Create stacked or grouped bar plots: You can create stacked or grouped bar plots by setting the stacked or groupby parameters, respectively. Stacked bar plots show multiple bars stacked on top of each other, while grouped bar plots show multiple bars side-by-side.\n",
    "- Create box plots: You can create box plots by setting the kind parameter to 'box'.\n",
    "- Create area plots: You can create area plots by setting the kind parameter to 'area'.\n",
    "- Create pie charts: You can create pie charts by setting the kind parameter to 'pie'.\n",
    "- Set the style and color of the plot: You can customize the style and color of the plot by setting the style and color parameters, respectively.\n",
    "- Display multiple plots on the same figure: You can display multiple plots on the same figure by creating a subplot using the subplots function and passing the returned axis object to the plot function.\n",
    "- Create log-scale plots: You can create log-scale plots by setting the logx or logy parameters to True.\n",
    "- Save the plot as an image: You can save the plot as an image by using the savefig function.\n",
    "\n",
    "Here is an example of how to use the plot function to create a stacked bar plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685d9adf-6118-4e39-a95d-3542b3fc6427",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a sample DataFrame\n",
    "data = pd.DataFrame({'A': [1, 2, 3],\n",
    "                     'B': [4, 5, 6],\n",
    "                     'C': [7, 8, 9]})\n",
    "\n",
    "# Create a stacked bar plot\n",
    "data.plot(kind='bar', stacked=True)\n",
    "\n",
    "# Add title and axis labels\n",
    "plt.title('Sample Stacked Bar Plot')\n",
    "plt.xlabel('X-axis')\n",
    "plt.ylabel('Y-axis')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1c2a03-4c10-42ea-a5bc-0625646c333b",
   "metadata": {},
   "source": [
    "This code will create a stacked bar plot of the data in the DataFrame, with each bar showing the values of the 'A', 'B', and 'C' columns. The plot will also have a title and axis labels.\n",
    "\n",
    "You can add multiple plots to the same figure using Pandas by creating subplots and passing the returned axis object to the plot function. The subplots function creates a grid of subplots with the specified number of rows and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593d6ac4-e1d8-4d7b-bb89-c26231ed32fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a sample DataFrame\n",
    "data = pd.DataFrame({'x': [1, 2, 3, 4],\n",
    "                     'y1': [10, 20, 30, 40],\n",
    "                     'y2': [5, 15, 25, 35]})\n",
    "\n",
    "# Create a subplot with two rows and one column\n",
    "fig, axes = plt.subplots(nrows=2, ncols=1)\n",
    "\n",
    "# Plot the first data series on the first subplot\n",
    "data.plot(x='x', y='y1', kind='line', ax=axes[0])\n",
    "\n",
    "# Plot the second data series on the second subplot\n",
    "data.plot(x='x', y='y2', kind='line', ax=axes[1])\n",
    "\n",
    "# Add title and axis labels to the figure\n",
    "fig.suptitle('Sample Multiple Plots')\n",
    "axes[0].set_ylabel('Y1-axis')\n",
    "axes[1].set_xlabel('X-axis')\n",
    "axes[1].set_ylabel('Y2-axis')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebaeb843-8956-441b-a4b3-a4dc98bbbec4",
   "metadata": {},
   "source": [
    "This code will create a figure with two subplots, each displaying a line plot of a different data series from the DataFrame. The subplot function returns a tuple containing the figure object and an array of axis objects. The ax parameter is used to specify which axis object to use for each plot. The suptitle, set_xlabel, and set_ylabel functions are used to add a title and axis labels to the figure.\n",
    "\n",
    "You may be wondering at this point why Matplotlib is being used. Matplotlib is used to add a title and axis labels to the figure. While the plot function in Pandas provides basic plotting functionality and allows you to create many types of plots with just one line of code, it may not provide all the customization options you need to create publication-quality plots.\n",
    "\n",
    "Matplotlib is a powerful plotting library in Python that provides many customization options for creating high-quality plots. You can use Matplotlib in combination with Pandas to customize your plots and add more advanced features, such as annotations, legends, and custom color maps.\n",
    "\n",
    "In the last example, after creating the subplots with Pandas, Matplotlib is used to add a title and axis labels to the figure. The suptitle, set_xlabel, and set_ylabel functions are provided by Matplotlib and are used to customize the figure created by Pandas.\n",
    "\n",
    "In summary, while Pandas provides basic plotting functionality, Matplotlib can be used to customize your plots and add more advanced features, and is often used in combination with Pandas to create high-quality plots.\n",
    "\n",
    "Some other useful visualizations follow to get you thinking about being creative with your plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6591bc-c24e-4435-8fe0-4e1ff8ca78b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all data from a DataFrame in a matrix plot to examine the relationships between the data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create dataframe and fill with random generated data\n",
    "df = pd.DataFrame(np.random.randn(1000, 4), columns=[\"a\", \"b\", \"c\", \"d\"])\n",
    "\n",
    "# Plot all data in one matrix using scatter plots with kde distribution plots on the diagonal axis\n",
    "pd.plotting.scatter_matrix(df, alpha=0.2, figsize=(6, 6), diagonal=\"kde\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd0bbb1-7e23-4c36-81aa-5fcee9c9e45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and plot a dataframe of four columns of random data and label with dates\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a Series of dates that we will use as an index\n",
    "ts = pd.Series(np.random.randn(1000), index=pd.date_range(\"1/1/2000\", periods=1000))\n",
    "\n",
    "# Create DataFrame with four columns (ABCD) and fill with random data and label with the date Series ts\n",
    "df = pd.DataFrame(np.random.randn(1000, 4), index=ts.index, columns=list(\"ABCD\"))\n",
    "\n",
    "# Return the cumulative sum over the DataFrame\n",
    "df = df.cumsum()\n",
    "\n",
    "# Plot the cumulative sum data\n",
    "df.plot(legend=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70eb9073-528a-4747-ae75-2a59986babdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the same data, plot A and B on separate axis\n",
    "# Note how different this plot is from keeping the data on the same axis\n",
    "\n",
    "df['A'].plot();\n",
    "\n",
    "df['B'].plot(secondary_y=True, style='g');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d9f656-96bf-4105-bdc5-4afac71829d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this data can also be easily plotted separately by adding the subplots keyword\n",
    "\n",
    "df.plot(subplots=True, figsize=(6, 6));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420437e4-4406-4319-a1ff-6703f0ad9be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also control the layout and plot individual data\n",
    "df.plot(subplots=True, layout=(2, 3), figsize=(6, 6), sharex=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7653293-306c-4e36-9604-c075895e1814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A helpful tip, we can also let Pandas calculate the number of rows\n",
    "# or columns needed by replacing one of the respective value with -1.\n",
    "\n",
    "\n",
    "# control number of rows (2) but not columns\n",
    "df.plot(subplots=True, layout=(2, -1), figsize=(6, 6), sharex=False);\n",
    "\n",
    "\n",
    "# control number of columns (3) but not rows\n",
    "df.plot(subplots=True, layout=(-1, 3), figsize=(6, 6), sharex=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e22f03-d353-4bd9-9a4c-cdc7752c77dd",
   "metadata": {},
   "source": [
    "This is a small selection of the possible plotting options available to you. Try to be creative with your plotting.\n",
    "\n",
    "*** \n",
    "\n",
    "### Seaborn\n",
    "\n",
    "Recommended Tutorial for capabilities, ideas, and code: https://seaborn.pydata.org/tutorial/introduction.html\n",
    "\n",
    "Below is another example of plotting DataFrames, but for this section we will use the Seaborn library. Seaborn is a Python data visualization library based on matplotlib. It provides a high-level interface for creating informative and attractive statistical graphics. Seaborn comes with several built-in themes and color palettes to enhance the visual aesthetics of plots.\n",
    "\n",
    "Seaborn is often used for statistical data visualization and exploration, and it includes several types of plots, including scatter plots, line plots, bar plots, histograms, kernel density plots, box plots, violin plots, heatmaps, and more. Seaborn also provides support for complex data types such as multi-panel categorical plots, and it can also be used for visualizing relationships between variables using techniques such as linear regression or correlation analysis. Overall, Seaborn is a powerful and flexible library for creating high-quality data visualizations in Python.\n",
    "\n",
    "We will use historical NBA performance data. First we will need to get the data. We can either download it directly or we can use Python to pull it in as it is needed and temporarily store it rather than on our drive. This can be very helpful when using online data sources or if we don't want to store the data on our system.\n",
    "\n",
    "Download: https://github.com/fivethirtyeight/data/tree/master/nba-elo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81a68c3-4390-4592-927c-53c5c19502f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the NBA Elo dataset from the online source \n",
    "nba_elo_df = pd.read_csv('https://raw.githubusercontent.com/fivethirtyeight/data/master/nba-elo/nbaallelo.csv')\n",
    "\n",
    "# Print the first few rows of the DataFrame to verify that the data was loaded correctly\n",
    "print(nba_elo_df.head())\n",
    "\n",
    "# Print the column names so that we know what data might be available\n",
    "print('\\n\\n', 'Columns in NBA Dataset')\n",
    "for col in nba_elo_df.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ec323f-44f0-4ba7-934f-b9e9d813921f",
   "metadata": {},
   "source": [
    "Now that we have the data and have a basic understanding of what might be avialable, lets start plotting it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edffe37-2e6b-47f1-b215-ea303c8b467b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bar chart showing the total number of points scored by the top ten franchises during playoffs across all time\n",
    "\n",
    "# We need to first group the data we want. From our prompt, \n",
    "    # we only want data from playoff games\n",
    "    # we want to group it by franchise\n",
    "    # we want to summarize all data available (across all time included)\n",
    "\n",
    "# First select only data from playoff games using conditionals \n",
    "playoffs_true = nba_elo_df['is_playoffs'] == True \n",
    "# Now we have found where the is_playoffs column is True (outputs True/False for each row)\n",
    "\n",
    "# separate all of the columns where it is a playoff game (only outputs the rows where True)\n",
    "nba_playoffs = nba_elo_df[playoffs_true] \n",
    "# Now we have only the playoff data\n",
    "\n",
    "# group the data by franchise ID\n",
    "nba_playoffs_grouped = nba_playoffs.groupby('fran_id')\n",
    "\n",
    "# find the sum of the points columns\n",
    "nba_playoffs_grouped_sum = nba_playoffs_grouped['pts'].sum().reset_index()\n",
    "\n",
    "# sort the DataFrame based on points\n",
    "nba_playoffs_sorted = nba_playoffs_grouped_sum.sort_values('pts', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# keep only the top ten teams\n",
    "top_ten = nba_playoffs_sorted.head(10)\n",
    "\n",
    "# output the top ten to check our work\n",
    "print(top_ten)\n",
    "\n",
    "# now we can plot the data\n",
    "sns.barplot(data=top_ten, x='fran_id', y='pts');\n",
    "\n",
    "# plot formatting\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel('Franchise ID')\n",
    "plt.ylabel('Number of points')\n",
    "plt.title('Top 10 Number of points scored per franchise');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8862c93d-1597-49ee-85e7-59206e42cde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The last script showed you step by step how to get to the data we desired. \n",
    "# Commonly, you will see this in shortform which you also use as you become more comfortable with python\n",
    "# The below two lines do the same thing as the six lines we used previously. This can also be made \n",
    "# into one line but for readability, it is two lines here. The functions are applied in a left to right manner. \n",
    "\n",
    "champions_df = nba_elo_df[nba_elo_df['is_playoffs'] == True].groupby('fran_id')['pts'].sum().reset_index()\n",
    "champions_df = champions_df.sort_values('pts', ascending=False).head(10).reset_index(drop=True)\n",
    "\n",
    "print(champions_df)\n",
    "\n",
    "sns.barplot(data=champions_df, x='fran_id', y='pts');\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel('Franchise ID')\n",
    "plt.ylabel('Number of points')\n",
    "plt.title('Top 10 Number of points scored per franchise');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faee7b87-e303-47b5-a71f-fe79fcfbaf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a line plot of the Elo rating over time for the Boston Celtics\n",
    "team = 'Celtics'\n",
    "\n",
    "boston_df = nba_elo_df[nba_elo_df['fran_id'] == team]\n",
    "sns.lineplot(data=boston_df, x='year_id', y='elo_n')\n",
    "\n",
    "# plot formatting using matplotlib\n",
    "plt.title(f'{team} Elo rating by year'); # we can use python fstrings to dynamically update our plots for us\n",
    "# the ; here suppresses text output from the plt function. \n",
    "# Depending on your Jupyter settings, you may or may not see this text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad987ed7-e472-4aa9-bd9e-814f3a6e34d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot of the Elo rating vs. the Equivalent number of wins for all games in the 2014-2015 season\n",
    "season_df = nba_elo_df[nba_elo_df['year_id'] == 2014]\n",
    "sns.scatterplot(data=season_df, x='elo_n', y='win_equiv')\n",
    "\n",
    "# Plot formatting\n",
    "plt.title('Elo rating vs Equivalent number of wins for all games in 2014-2015 season');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97bde29-4846-442e-afc8-35121968287c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a box plot of the Elo rating by team for the 2014-2015 season\n",
    "season_df = nba_elo_df[nba_elo_df['year_id'] == 2014]\n",
    "sns.boxplot(data=season_df, x='fran_id', y='elo_n')\n",
    "\n",
    "# plot formatting\n",
    "plt.xticks(rotation=90); # the ; here suppresses text output from the plt function. Depending on your Jupyter settings, you may or may not see this text\n",
    "plt.xlabel('Franchise ID') \n",
    "plt.ylabel('Team Elo following game')\n",
    "plt.title('Elo rating by team for 2014-2015 season');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55c4afa-6d80-4048-8e55-fdc30738ce74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also examine this data a pivot table to examine the historical mean points the \n",
    "# team scored based on location (Home-H, Away-A) and whether they won (W) or lost (L)\n",
    "\n",
    "pivot_table = pd.pivot_table(nba_elo_df, index=['fran_id', 'game_location'], columns='game_result', values='pts', aggfunc='mean')\n",
    "\n",
    "print(pivot_table.head(15)) # Print the first 15 rows of the output\n",
    "print('\\n') # Add a blank line between output\n",
    "\n",
    "# Print the same table but let's display only 1 decimal point\n",
    "print(pivot_table.head(15).round(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c3679e-44e9-4d19-b3cf-56a6cf6a1902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now plot the pivot table to make it quick to reference highs (dark blue) and lows (light green)\n",
    "\n",
    "# This is alot of data to plot, we have to manually set the size of the plot so that everything is visible\n",
    "# Since Seaborn is based on Matplotlib, we can use it to our advantage and set the size of the plot \n",
    "# by making a 1x1 subplot in the size desired.\n",
    "fig, ax = plt.subplots(figsize=(5, 40))\n",
    "\n",
    "# plot the data in a heatmap with the YlGnBu colormap and place it in the current plot ax\n",
    "sns.heatmap(data=pivot_table, cmap='YlGnBu', ax=ax); \n",
    "plt.show()\n",
    "\n",
    "# Seaborn has great colormaps available and you can define your own\n",
    "# Find more info here: https://seaborn.pydata.org/tutorial/color_palettes.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8407db-4126-4f72-ba1d-824b9feac4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a heatmap showing the frequency of home team victories by year and location\n",
    "victories_df = nba_elo_df[nba_elo_df['game_result'] == 'W'].groupby(['year_id', 'game_location'])['game_result'].count().reset_index()\n",
    "victories_pivot = victories_df.pivot_table(values='game_result', index='game_location', columns='year_id', aggfunc='sum')\n",
    "\n",
    "sns.heatmap(data=victories_pivot, cmap='YlGnBu');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0d7d68-77b0-4ee4-b5f7-cef228c62c04",
   "metadata": {},
   "source": [
    "[Return to top](#Start)\n",
    "***\n",
    "<a name=\"End\"></a>\n",
    "\n",
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
